# Enhanced Destination Intelligence System

An advanced AI-powered system for discovering, analyzing, and providing comprehensive insights about travel destinations with **semantic priority data extraction**, multi-dimensional scoring, local authority validation, seasonal intelligence, sophisticated content classification, and a comprehensive 4-layer caching system for optimal performance.

## üöÄ **Latest Updates**

### **üß† New: Semantic Priority Data Extraction**
- **LLM-Powered Analysis**: Replaced regex-based extraction with semantic understanding using Google Gemini and OpenAI
- **Context Awareness**: Correctly categorizes "$35 visa" vs "$35 meal" vs "$35 hotel"
- **Synonym Recognition**: Understands "tourist police" = "tourism officers" = "tourist assistance"
- **Natural Language Understanding**: Processes "remarkably secure" as safe, "mandatory" as required
- **Fallback Mode**: Graceful degradation when LLM unavailable
- **Rich Metadata**: Confidence scores, source credibility, temporal relevance

### **‚úÖ Production Ready**
- **163 Tests Passing** (100% success rate): 143 unit + 20 integration tests
- **Multiple LLM Providers**: Gemini and OpenAI support with auto-detection
- **Comprehensive Validation**: All semantic extraction features tested and validated
- **Immediate Use**: Ready to run with `python run_enhanced_agent_app.py`

## Overview

This system uses CrewAI agents, LangChain tools, semantic LLM extraction, and multi-agent validation to:
- **Discover destination information** from web sources with intelligent priority data extraction
- **Extract and validate insights** with evidence-based confidence scoring and semantic understanding
- **Analyze themes and attractions** with multi-dimensional authenticity scoring
- **Track seasonal variations** and provide temporal insights
- **Generate enhanced intelligence** with local authority validation
- **Store insights** in a structured database with ChromaDB for semantic search
- **Cache all operations** across 4 layers for optimal performance and reliability

## üéØ **Key Features**

### **üß† Semantic Priority Data Extraction** *(NEW)*
- **LLM-Powered Understanding**: Uses Google Gemini or OpenAI for natural language comprehension
- **Context-Aware Parsing**: Distinguishes between different types of costs, safety ratings, and requirements
- **Intelligent Classification**: Automatically categorizes safety, cost, health, and accessibility information
- **Source Credibility Assessment**: Evaluates source authority (government, academic, travel platforms, etc.)
- **Temporal Relevance Scoring**: Assesses information freshness and currency
- **Confidence Metrics**: Provides extraction confidence and data completeness scores
- **Fallback Mode**: Continues operation when LLM unavailable with graceful degradation

### **Core Intelligence Features**
- **Web Discovery**: Automated discovery of destination information from multiple sources
- **Enhanced Theme Analysis**: Evidence-based theme extraction with multi-dimensional scoring
- **Multi-Agent Validation**: Specialized agents for data validation and contradiction detection
- **Cultural Perspective**: Analysis of cultural context and local insights
- **Temporal Analysis**: Seasonal tracking and pattern recognition
- **Local Authority Validation**: Integration of local expertise and community validation

### **Enhanced Features**
- **Multi-Dimensional Scoring**: Authenticity, uniqueness, and actionability scoring
- **Evidence Hierarchy**: Advanced source classification with local authority patterns
- **Seasonal Intelligence**: Seasonal pattern extraction and timing recommendations
- **Insight Classification**: Content classification by type and location exclusivity
- **Destination Classification**: Destination type classification with appropriate scoring strategies
- **Confidence Scoring**: Comprehensive confidence assessment with multiple factors

### **üóÑÔ∏è High-Performance Caching System**
- **4-Layer Architecture**: File, Web Discovery, Vector Database, and SQLite caching
- **Massive Performance Gains**: 5,575x faster API calls, 70x faster content processing
- **Intelligent Cache Management**: Automatic expiry, corruption recovery, concurrent access
- **Comprehensive Testing**: 45 tests across all caching layers with 100% success rate

### **Validation & Quality**
- **Enhanced Validation Agents**: Specialized validators for each data category
- **Confidence Breakdown**: Multi-level confidence assessment for all insights
- **Source Credibility**: Authority-based weighting of information sources
- **Contradiction Resolution**: Automatic detection and resolution of conflicting data

## üì¶ **Installation**

1. **Clone the repository:**
```bash
git clone <repository-url>
cd DestinationIntelligence
```

2. **Create and activate a virtual environment:**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
```

4. **Set up environment variables:**
```bash
cp .env.example .env
# Edit .env with your API keys:
# - GEMINI_API_KEY (required for semantic extraction)
# - BRAVE_SEARCH_API_KEY (required for web discovery)
# - OPENAI_API_KEY (optional alternative to Gemini)
# - JINA_API_KEY (optional for enhanced content extraction)
```

5. **Configure settings:**
```bash
cp config.yaml.example config.yaml
# Edit config.yaml for your preferences
```

## üöÄ **Usage**

### **Running the Enhanced Agent Application**

The application supports multiple LLM providers with automatic detection:

```bash
# Auto-detect and use available LLM provider
python run_enhanced_agent_app.py

# Use specific provider
python run_enhanced_agent_app.py --provider gemini
python run_enhanced_agent_app.py --provider openai

# Use specific model
python run_enhanced_agent_app.py --provider gemini --model gemini-2.0-flash
python run_enhanced_agent_app.py --provider openai --model gpt-4o-mini

# List available providers and models
python run_enhanced_agent_app.py --list-providers
```

**Example Output:**
```
üöÄ ENHANCED CrewAI-Inspired Destination Intelligence Application
ü§ñ Using GEMINI LLM with model: gemini-2.0-flash
‚úÖ Semantic priority data extraction enabled
üìä Features: Evidence-based confidence, cultural perspective, temporal intelligence
```

### **Application Workflow**

The application will automatically:
1. **Discover web content** about your destination using Brave Search API
2. **Extract priority data** (safety, cost, health, accessibility) using semantic analysis
3. **Analyze themes** with multi-dimensional scoring and local authority validation
4. **Generate insights** with seasonal intelligence and cultural context
5. **Store results** in enhanced database with JSON export
6. **Cache operations** for faster subsequent runs

### **Interactive Features**

- **Destination Selection**: Choose from configured destinations or enter custom names
- **Processing Settings**: Configure confidence thresholds and analysis depth
- **Real-time Progress**: See processing progress with detailed metrics
- **Results Export**: Automatic JSON export with timestamped files

## üß™ **Testing the System**

### **‚úÖ Current Test Status: 163 Tests Passing (100% Success Rate)**

The system includes comprehensive testing across all components:

#### **üìä Test Summary**
- **143 Unit Tests** across 11 test files
- **20 Integration Tests** across 3 test files
- **100% Success Rate** with semantic extraction
- **Fallback Mode Testing** validates graceful degradation
- **Performance Benchmarks** included

### **Running Tests**

#### **Complete Test Suite** *(Recommended)*
```bash
# Run ALL tests with comprehensive reporting
python tests/run_all_tests.py

# Output includes:
# ‚úÖ Unit Tests: 143/143 passed (100%)
# ‚úÖ Integration Tests: 20/20 passed (100%)
# üéâ ALL TESTS PASSED SUCCESSFULLY!
```

#### **Core Intelligence Tests**
```bash
# Run all unit tests
python -m pytest tests/unit/ -v

# Run specific test modules
python -m pytest tests/unit/test_priority_data_extraction_tool.py -v  # NEW: Semantic extraction
python -m pytest tests/unit/test_enhanced_theme_analysis_tool.py -v   # Enhanced themes
python -m pytest tests/unit/test_confidence_scoring.py -v             # Multi-dimensional scoring
python -m pytest tests/unit/test_seasonal_intelligence.py -v          # Seasonal analysis

# Test semantic vs fallback modes
python -m pytest tests/unit/test_priority_data_extraction_tool.py::TestPriorityDataExtractionTool::test_extract_safety_metrics_comprehensive -v
```

#### **Integration Tests**
```bash
# Run integration tests
python -m pytest tests/integration/ -v

# Test enhanced field persistence
python -m pytest tests/integration/test_enhanced_fields_comprehensive.py -v

# Test caching integration
python -m pytest tests/integration/test_caching_layers.py -v
```

#### **Caching System Tests**
```bash
# Run complete caching test suite
python tests/run_cache_tests.py

# Individual cache test categories
python -m pytest tests/unit/test_cache_utilities.py -v           # File cache (19 tests)
python -m pytest tests/integration/test_caching_layers.py -v     # Multi-layer integration (17 tests)
python -m pytest tests/performance/test_cache_performance.py -v  # Performance benchmarks (8 tests)
```

### **Test Categories Explained**

#### **üß† Semantic Extraction Tests** *(NEW - 22 tests)*
**File**: `test_priority_data_extraction_tool.py`

Tests the new semantic priority data extraction system:

- **Data Models**: SafetyMetrics, CostIndicators, HealthRequirements, AccessibilityInfo
- **Semantic Extraction**: LLM-powered analysis with context awareness
- **Fallback Mode**: Graceful degradation when LLM unavailable
- **Source Credibility**: Authority-based scoring (government, academic, travel platforms)
- **Temporal Relevance**: Content freshness and currency assessment
- **Edge Cases**: Malformed content, concurrent extraction, large content processing

**Key Features Tested**:
- Context-aware extraction ("$35 visa" vs "$35 meal")
- Synonym recognition ("tourist police" = "tourism officers")
- Confidence and completeness scoring
- Fallback mode detection and handling
- Source credibility calculation
- Temporal relevance determination

#### **üé® Enhanced Theme Analysis Tests** *(Updated - 12 tests)*
**File**: `test_enhanced_theme_analysis_tool.py`

Tests the enhanced theme analysis with semantic integration:

- **Local Authority Detection**: Professional expertise and community validation
- **Seasonal Intelligence**: Pattern extraction and timing recommendations
- **Sentiment Analysis**: Multi-dimensional sentiment scoring
- **Cultural Context**: Local vs international source analysis
- **Evidence Classification**: Source type and authority scoring

#### **üìä Core Intelligence Tests** *(109 tests across 9 files)*

**Enhanced Data Models** (10 tests):
- AuthenticInsight, SeasonalWindow, LocalAuthority, EnhancedTheme, EnhancedDestination

**Schema Enumerations** (10 tests):
- InsightType, AuthorityType, LocationExclusivity validation

**Evidence Hierarchy** (8 tests):
- Source classification, local authority detection, diversity calculation

**Confidence Scoring** (16 tests):
- Authenticity, uniqueness, actionability scoring

**Insight Classification** (18 tests):
- Content type classification, exclusivity determination

**Destination Classification** (18 tests):
- Destination type classification, scoring strategy assignment

**Seasonal Intelligence** (12 tests):
- Pattern extraction, relevance calculation, timing recommendations

**Cache Utilities** (19 tests):
- File operations, expiration logic, error handling

**Schemas** (10 tests):
- Enum validation and consistency checking

#### **üîó Integration Tests** *(20 tests across 3 files)*

**Enhanced Fields Validation**: End-to-end enhanced field processing
**Enhanced Fields Comprehensive**: Database persistence and JSON export
**Caching Layers**: Multi-layer cache coordination and performance

### **Test Data Examples**

The test suite uses realistic travel scenarios:

**Destinations**:
- Tokyo, Japan (global hub) - Professional sushi chef recommendations
- Vermont, USA (regional) - Fall foliage and maple syrup seasons
- Bangkok, Thailand (global hub) - Safety, cost, and accessibility data
- Mountain Resort (remote getaway) - Seasonal activities and insider tips

**Content Types**:
- Safety information: Crime indices, travel advisories, emergency contacts
- Cost data: Budget ranges, meal costs, accommodation prices, seasonal variations
- Health requirements: Vaccinations, health risks, water safety, medical facilities
- Accessibility: Visa requirements, flight connections, English proficiency

**Source Types**:
- Government sites: travel.state.gov, gov.uk, embassy sites
- Travel platforms: TripAdvisor, Lonely Planet, Fodor's
- News sources: BBC, CNN, Reuters
- Community content: Reddit, forums, local blogs

## üß† **Semantic Priority Data Extraction**

### **How It Works**

The semantic extraction system uses advanced LLM analysis to understand travel content:

#### **Context Awareness**
```
Traditional Regex: "$35" ‚Üí Always extracted as generic cost
Semantic System:   "$35 visa fee" ‚Üí Accessibility cost
                  "$35 per meal" ‚Üí Meal cost average  
                  "$35 hotel rate" ‚Üí Accommodation cost
```

#### **Natural Language Understanding**
```
Content: "The area is remarkably secure with excellent tourist assistance"
Regex:   Misses "secure" (not exact match for "safe")
Semantic: ‚úÖ Safety rating: High, Tourist police: Available
```

#### **Synonym Recognition**
```
Various Terms ‚Üí Unified Understanding:
"tourist police" = "tourism officers" = "tourist assistance officers"
"travel advisory" = "safety warning" = "government alert"
"visa on arrival" = "arrival visa" = "VOA"
```

### **Extraction Categories**

#### **üõ°Ô∏è Safety Metrics**
- **Crime indices and safety ratings**
- **Tourist police availability**
- **Emergency contact numbers**
- **Travel advisory levels**
- **Safe areas and areas to avoid**

#### **üí∞ Cost Indicators**
- **Daily budget ranges (low/mid/high)**
- **Meal and accommodation costs**
- **Transportation expenses**
- **Currency and exchange information**
- **Seasonal price variations**

#### **üè• Health Requirements**
- **Required vs recommended vaccinations**
- **Health risks and disease information**
- **Water and food safety**
- **Medical facility quality**
- **Health insurance requirements**

#### **üõÇ Accessibility Information**
- **Visa requirements and costs**
- **Direct flight connections**
- **English proficiency levels**
- **Infrastructure quality ratings**
- **Average flight times**

### **Quality Metrics**

Each extraction includes comprehensive quality assessment:

- **Extraction Confidence** (0-1): Overall reliability of extracted data
- **Data Completeness** (0-1): Percentage of fields successfully populated  
- **Source Credibility** (0-1): Authority level of information source
- **Temporal Relevance** (0-1): Freshness and currency of information

### **Fallback Mode**

When LLM is unavailable, the system:
- ‚úÖ Continues operation with basic structure
- ‚úÖ Maintains data integrity and format consistency
- ‚úÖ Provides clear indication of extraction method
- ‚úÖ Logs appropriate warnings without crashing

## üèóÔ∏è **System Architecture**

### **Enhanced Components**

#### **1. üß† Semantic Priority Data Extraction** *(NEW)*
**File**: `priority_data_extraction_tool.py`

- **PriorityDataExtractor**: Main semantic extraction class
- **Pydantic Models**: SafetyMetricsPydantic, CostIndicatorsPydantic, etc.
- **LLM Integration**: Google Gemini and OpenAI support
- **Fallback Mode**: Graceful degradation capabilities
- **Quality Assessment**: Confidence and credibility scoring

#### **2. üéØ Priority Data Aggregation** *(Enhanced)*
**File**: `priority_aggregation_tool.py`

- **Multi-Source Aggregation**: Combines semantic extractions from multiple sources
- **Consensus Analysis**: Weighted averaging based on source credibility
- **Confidence Thresholding**: Filters data based on reliability
- **Temporal Weighting**: Prioritizes more recent information

#### **3. üåê Web Discovery** *(Enhanced)*
**File**: `web_discovery_tools.py`

- **Semantic Integration**: Uses semantic extraction during content discovery
- **Priority Type Detection**: Identifies high-value content for priority data
- **Source Quality Assessment**: Evaluates and ranks discovered sources
- **Caching Integration**: Leverages 4-layer caching for performance

#### **4. üé® Enhanced Theme Analysis**
**File**: `enhanced_theme_analysis_tool.py`

- Multi-dimensional scoring with authenticity, uniqueness, and actionability
- Local authority validation and seasonal intelligence integration
- Advanced evidence hierarchy classification

#### **5. üìä Confidence Scoring**
**File**: `confidence_scoring.py`

- AuthenticityScorer, UniquenessScorer, ActionabilityScorer
- Comprehensive confidence breakdown with multiple factors
- Evidence quality assessment and source diversity calculation

#### **6. üìã Evidence Hierarchy**
**File**: `evidence_hierarchy.py`

- Advanced source classification with local authority patterns
- Seasonal indicators and diversity calculations
- Cultural context and relationship tracking

#### **7. üîç Insight Classification**
**File**: `insight_classifier.py`

- Content classification by type (seasonal, specialty, insider, cultural, practical)
- Location exclusivity determination (exclusive, signature, regional, common)
- Seasonal window extraction and actionable detail extraction

#### **8. üè¢ Destination Classification**
**File**: `destination_classifier.py`

- Destination type classification (global hub, regional, business hub, remote getaway)
- Appropriate scoring weights and source strategies per destination type
- Population and infrastructure-based classification logic

#### **9. üåø Seasonal Intelligence**
**File**: `seasonal_intelligence.py`

- Seasonal pattern extraction and current relevance calculation
- Timing recommendations and seasonal window analysis
- Month-based analysis and seasonal content detection

#### **10. üóÑÔ∏è Caching System**
**Files**: `caching.py`, `chroma_interaction_tools.py`

- **File-Based Caching**: MD5-hashed JSON storage with timestamp management
- **Web Discovery Caching**: API response and content caching with BeautifulSoup integration
- **Vector Database Caching**: ChromaDB semantic search with persistence
- **Database Caching**: Enhanced SQLite storage with performance optimization

### **Enhanced Database Schema**

The system uses SQLite with the following enhanced tables:

- `destinations`: Enhanced destination information with admin levels and metadata
- `themes`: Themes with confidence breakdown, authentic insights, and local authorities
- `evidence`: Complete evidence tracking with cultural context and relationships
- `authentic_insights`: Multi-dimensional insights with seasonal windows
- `seasonal_windows`: Time-sensitive availability and booking information
- `local_authorities`: Local expertise and community validation data
- `dimensions`: 60-dimension matrix for comprehensive destination profiling
- `temporal_slices`: Seasonal tracking with SCD2 versioning
- **`priority_metrics`** *(NEW)*: Semantic priority data with quality metrics

**Performance Optimizations**:
- 15+ database indices for optimal query performance
- Evidence confidence and destination-based indexing
- Theme category and destination indexing
- **Priority data indices** for semantic extraction results
- Transaction safety with ACID compliance

### **Data Flow**

1. **Discovery Phase**: Web discovery finds relevant content *(with semantic priority extraction)*
2. **Semantic Extraction Phase**: LLM-powered priority data extraction with quality assessment
3. **Enhanced Analysis Phase**: Multi-dimensional scoring and classification
4. **Validation Phase**: Multi-agent validation with local authority integration
5. **Aggregation Phase**: Priority data aggregation with consensus analysis
6. **Intelligence Phase**: Seasonal intelligence and insight classification
7. **Storage Phase**: All data stored in enhanced database schema *(with caching)*
8. **Export Phase**: JSON exports with complete semantic annotations *(with file caching)*

### **Cache Data Flow**

```
API Request ‚Üí File Cache Check ‚Üí Cache Hit? ‚Üí Return Cached Data
                      ‚Üì (Miss)
             Web Discovery Cache ‚Üí API Call ‚Üí Semantic Extraction ‚Üí Process ‚Üí Store in Cache
                      ‚Üì
             ChromaDB Vector Cache ‚Üí Semantic Search ‚Üí Store Embeddings
                      ‚Üì  
             Database Cache ‚Üí SQLite Storage ‚Üí JSON Export ‚Üí File Cache
```

## üìã **Dependencies**

### **Core Requirements** (`requirements.txt`)
```
# LLM and Semantic Processing
google-generativeai==0.8.5          # Gemini API integration
langchain==0.3.25                    # LLM framework
langchain-google-genai==2.0.10       # Gemini LangChain integration
langchain-community                  # Additional LangChain tools
langchain-core                       # Core LangChain types
pydantic                             # Data validation and parsing

# Web Discovery and Processing
aiohttp==3.12.6                      # Async HTTP client
beautifulsoup4==4.13.4               # HTML parsing
retry==0.9.2                         # Retry logic
python-dotenv==1.1.0                 # Environment variables

# AI and Vector Processing
transformers==4.52.4                 # HuggingFace transformers
torch==2.2.2                         # PyTorch for embeddings
chromadb==1.0.12                     # Vector database

# Workflow Orchestration
crewai==0.121.1                      # Multi-agent workflows

# Utilities
PyYAML==6.0.2                        # Configuration files
tqdm==4.67.1                         # Progress bars
tabulate==0.9.0                      # Table formatting
colorama==0.4.6                      # Colored output
```

### **Optional Dependencies**
- **OpenAI Integration**: Automatically included with langchain
- **Jina Reader API**: For enhanced content extraction
- **Additional LangChain Tools**: As needed for specific features

## üìÑ **Output Examples**

### **üß† Semantic Priority Data Extraction Output**
```json
{
  "safety": {
    "crime_index": 45.2,
    "safety_rating": 6.8,
    "tourist_police_available": true,
    "emergency_contacts": {
      "police": "191",
      "ambulance": "1669",
      "fire": "199"
    },
    "travel_advisory_level": "Level 2",
    "safe_areas": ["Sukhumvit", "Silom", "Tourist Zone"],
    "areas_to_avoid": ["Klong Toey Port area"]
  },
  "cost": {
    "budget_per_day_low": 25.0,
    "budget_per_day_mid": 65.0,
    "budget_per_day_high": 150.0,
    "meal_cost_average": 8.5,
    "accommodation_cost_average": 45.0,
    "currency": "THB",
    "seasonal_price_variation": {
      "high_season": 20.0,
      "low_season": -15.0
    }
  },
  "extraction_metadata": {
    "extraction_method": "semantic_llm",
    "extraction_confidence": 0.87,
    "data_completeness": 0.92,
    "source_credibility": 0.85,
    "temporal_relevance": 0.95,
    "extraction_timestamp": "2024-06-02T21:45:00Z"
  }
}
```

### **Enhanced Theme Analysis Output**
```json
{
  "theme_name": "Craft Brewery Scene",
  "confidence_breakdown": {
    "overall_confidence": 0.85,
    "confidence_level": "high",
    "evidence_count": 12,
    "source_diversity": 0.73,
    "authority_score": 0.81
  },
  "authentic_insights": [
    {
      "insight_type": "insider",
      "authenticity_score": 0.88,
      "uniqueness_score": 0.76,
      "actionability_score": 0.92,
      "location_exclusivity": "signature"
    }
  ],
  "local_authorities": [
    {
      "authority_type": "producer",
      "local_tenure": 8,
      "expertise_domain": "brewing",
      "community_validation": 0.91
    }
  ],
  "seasonal_relevance": {
    "peak_season": "summer",
    "current_relevance": 0.95
  },
  "priority_data_integration": {
    "safety_relevant": true,
    "cost_implications": "moderate",
    "accessibility_notes": "Public transportation accessible"
  }
}
```

### **Priority Data Aggregation Output**
```json
{
  "aggregation_summary": {
    "total_sources": 8,
    "high_credibility_sources": 5,
    "consensus_level": 0.78,
    "temporal_coverage": "2023-2024"
  },
  "safety_consensus": {
    "crime_index_range": [42.1, 47.8],
    "agreed_value": 45.2,
    "confidence": 0.85,
    "supporting_sources": 6
  },
  "cost_consensus": {
    "budget_ranges_agreed": true,
    "seasonal_patterns_confirmed": true,
    "currency_consistent": "THB",
    "confidence": 0.91
  }
}
```

## ‚öôÔ∏è **Configuration**

### **Enhanced System Settings (config.yaml)**
```yaml
# LLM Provider Configuration
llm_settings:
  gemini_model_name: "gemini-2.0-flash"      # Latest Gemini model
  openai_model_name: "gpt-4o-mini"           # OpenAI alternative
  
# Processing Settings
processing_settings:
  max_destinations_to_process: 1
  
  # Semantic Extraction Settings
  semantic_extraction:
    enable_semantic_priority_data: true       # Enable LLM-powered extraction
    extraction_confidence_threshold: 0.7     # Minimum confidence for results
    fallback_mode_enabled: true              # Allow graceful degradation
    context_window_size: 4000                # Max tokens for LLM processing
    
  web_discovery:
    max_urls_per_destination: 10
    timeout_seconds: 30
    max_content_length: 2000000
    enable_priority_extraction: true         # Extract priority data during discovery
    priority_extraction_confidence: 0.6     # Threshold for priority data inclusion
    
  content_intelligence:
    min_validated_theme_confidence: 0.60
    min_discovered_theme_confidence: 0.60
    max_discovered_themes_per_destination: 5
    enable_semantic_integration: true        # Integrate priority data with themes
    
# Priority Data Extraction Configuration
priority_data:
  source_credibility:
    government_weight: 0.95
    academic_weight: 0.9
    travel_platform_weight: 0.85
    news_weight: 0.8
    community_weight: 0.7
    default_weight: 0.6
    
  temporal_relevance:
    current_year_bonus: 1.0
    recent_year_decay: 0.1
    recency_indicator_boost: 0.9
    default_relevance: 0.75
    
  extraction_quality:
    min_content_length: 50
    confidence_weights:
      content_length: 0.25
      data_completeness: 0.25
      source_credibility: 0.25
      temporal_relevance: 0.25

# Confidence Scoring
confidence_scoring:
  authenticity_weight: 0.4
  uniqueness_weight: 0.3
  actionability_weight: 0.3
  min_evidence_count: 3
  
# Seasonal Intelligence
seasonal_intelligence:
  enable_seasonal_analysis: true
  current_season_boost: 0.1
  seasonal_relevance_threshold: 0.6
  
# Destination Classification
destination_classification:
  enable_auto_classification: true
  population_thresholds:
    global_hub: 5000000
    regional: 500000
    business_hub: 200000

# Caching Configuration
caching:
  brave_search_expiry_days: 7
  page_content_expiry_days: 30
  enable_cache_compression: false
  
# Database Configuration
database:
  path: "enhanced_destination_intelligence.db"
  type: "sqlite"
  chroma_db_path: "./chroma_db"
  enable_performance_indices: true
  enable_priority_data_storage: true         # Store semantic extraction results

# Destinations to Process
destinations_to_process:
  - "Bangkok, Thailand"
  - "Bend, Oregon"
  - "Tokyo, Japan"
```

### **Environment Variables (.env)**
```bash
# Required for Semantic Extraction
GEMINI_API_KEY=your_gemini_api_key_here
BRAVE_SEARCH_API_KEY=your_brave_search_api_key_here

# Optional LLM Alternative
OPENAI_API_KEY=your_openai_api_key_here

# Optional Content Enhancement
JINA_API_KEY=your_jina_api_key_here

# Model Overrides (optional)
GEMINI_MODEL_NAME=gemini-2.0-flash
OPENAI_MODEL_NAME=gpt-4o-mini
```

## üóÑÔ∏è **Multi-Layer Caching Architecture**

The system implements a sophisticated **4-layer caching architecture** for optimal performance:

### **Layer 1: üìÅ File-Based Caching**
- **Purpose**: Primary caching for web content and API responses
- **Location**: `/cache/` directory with MD5-hashed JSON files
- **Performance**: Sub-millisecond read/write operations
- **Features**: 
  - Time-based expiration (7-30 days configurable)
  - Automatic corruption recovery
  - Thread-safe concurrent access
  - Unicode and special character support

### **Layer 2: üåê Web Discovery Caching**
- **Purpose**: Brave Search API results and web page content
- **Performance Benefits**: **5,575x** improvement for API calls, **70x** for content processing
- **Components**:
  - Search result caching (7-day expiry)
  - HTML content processing and storage (30-day expiry)
  - BeautifulSoup integration for reliable content extraction

### **Layer 3: üß† Vector Database Caching (ChromaDB)**
- **Purpose**: Semantic similarity search for content chunks
- **Performance**: 89+ searches per second, efficient storage
- **Features**:
  - Persistent across sessions
  - Semantic ranking and similarity scoring
  - Embedding vectors with comprehensive metadata

### **Layer 4: üóÑÔ∏è Database Caching (SQLite)**
- **Purpose**: Structured data persistence with JSON export
- **Features**:
  - Enhanced fields storage (sentiment, cultural_context, relationships)
  - **Priority data storage** with semantic annotations
  - Performance indices for optimal query speed
  - Complete CRUD operations with transaction safety
  - Automatic JSON export with timestamped files

### **Cache Performance Metrics**

| Cache Layer | Operation | Performance | Improvement |
|-------------|-----------|-------------|-------------|
| File Cache | Write (small) | 0.0003s | Baseline |
| File Cache | Write (large) | 0.007s | Scales well |
| File Cache | Read | 0.0006s | Very fast |
| Brave Search | API Cache Hit | 0.0002s | **5,575x faster** |
| Page Content | Cache Hit | 0.0001s | **70x faster** |
| ChromaDB | Storage | 0.003s/chunk | Efficient |
| ChromaDB | Search | 0.011s | 89 searches/sec |

## üö® **Troubleshooting**

### **Common Issues and Solutions**

#### **üß† Semantic Extraction Issues**

**1. "No valid API keys found"**
```bash
# Check your .env file
cat .env | grep -E "(GEMINI|OPENAI)_API_KEY"

# Verify API key validity
python run_enhanced_agent_app.py --list-providers
```

**2. "Semantic extraction failed, using fallback mode"**
- ‚úÖ **Normal behavior** when LLM unavailable
- Check logs for specific LLM initialization errors
- Verify internet connectivity and API quotas
- System continues with basic extraction

**3. "Low extraction confidence scores"**
- Review source quality and content length
- Check temporal relevance of content
- Verify content contains relevant priority data
- Adjust confidence thresholds in config.yaml

**4. "Inconsistent priority data results"**
- Enable priority data aggregation
- Increase number of sources processed
- Review source credibility weights
- Check for conflicting information in sources

#### **üîß General Application Issues**

**5. Low confidence scores**: Check if enough credible sources are available and evidence diversity
**6. Missing enhanced attributes**: Ensure enhanced analysis is enabled in config.yaml
**7. Classification errors**: Review destination data (population, admin levels) and classification thresholds
**8. Seasonal analysis issues**: Verify seasonal content is present and seasonal intelligence is enabled

#### **üóÑÔ∏è Cache Issues**

**9. Slow performance**: Check cache hit rates and disk space
**10. Corruption errors**: Cache system auto-recovers; check logs for details
**11. Memory usage**: ChromaDB uses ~31MB; file cache ~3MB typically

### **Debugging Tools**

#### **Semantic Extraction Diagnostics**
```bash
# Test semantic extraction directly
python -c "
from src.tools.priority_data_extraction_tool import PriorityDataExtractor
extractor = PriorityDataExtractor()
test_content = 'Bangkok is generally safe. Budget travelers: \$25 per day. Visa required \$35.'
result = extractor.extract_all_priority_data(test_content)
print('Extraction method:', result.get('extraction_method'))
print('Confidence:', result.get('extraction_confidence'))
print('Safety data:', bool(result.get('safety', {}).get('crime_index')))
"

# Check LLM availability
python -c "
from src.core.llm_factory import LLMFactory
from src.config_loader import load_app_config
config = load_app_config()
providers = LLMFactory.get_available_providers(config)
print('Available providers:', providers)
"
```

#### **General System Diagnostics**
```bash
# Check database schema
python -c "import sqlite3; conn=sqlite3.connect('enhanced_destination_intelligence.db'); print([x[0] for x in conn.execute('SELECT name FROM sqlite_master WHERE type=\"table\"').fetchall()])"

# Validate complete test suite
python tests/run_all_tests.py

# Quick validation
python -m pytest tests/unit/test_priority_data_extraction_tool.py -v

# Check configuration
python -c "import yaml; print(yaml.safe_load(open('config.yaml')))"
```

#### **Cache Diagnostics**
```bash
# Cache health check
python -c "
from src.caching import read_from_cache, write_to_cache
test_data = {'test': 'cache_check'}
write_to_cache(['diagnostic', 'test'], test_data)
result = read_from_cache(['diagnostic', 'test'], 1)
print('‚úÖ Cache working' if result == test_data else '‚ùå Cache issue')
"
```

### **Performance Optimization**

#### **For Large-Scale Processing**
1. **Increase cache retention**: Extend expiry days in config.yaml
2. **Batch processing**: Process multiple destinations in sequence
3. **LLM quota management**: Monitor API usage and implement rate limiting
4. **Memory optimization**: Clear ChromaDB periodically for large datasets

#### **For Development**
1. **Use fallback mode**: Disable LLM for faster testing
2. **Reduce processing scope**: Limit max_urls_per_destination
3. **Cache warming**: Run with same destinations to build cache

### **Logging and Monitoring**

#### **Log Files**
- **Main Application**: `logs/enhanced_app_run_YYYYMMDD_HHMMSS.log`
- **LangChain Agents**: `logs/enhanced_langchain_agent_trace_YYYYMMDD_HHMMSS.log`
- **Console Output**: Real-time progress and status updates

#### **Key Log Messages**
```
‚úÖ Semantic priority extractor initialized with configured LLM
‚ö†Ô∏è  Failed to initialize semantic extractor, using default (fallback mode)
üìä Semantic extraction completed for [URL]: confidence=0.87, completeness=0.92
üö® Semantic extraction failed: [error] (falls back gracefully)
```

## üîß **Cache Management**

### **Cache Directory Structure**
```
cache/                              # File-based cache (2.79 MB, 83 files)
‚îú‚îÄ‚îÄ [md5_hash].json                # Individual cache files
‚îî‚îÄ‚îÄ ...

chroma_db/                          # Vector database cache (31.50 MB, 6 files)
‚îú‚îÄ‚îÄ [collection_id]/               # ChromaDB collections
‚îî‚îÄ‚îÄ ...

destination_insights/               # JSON exports (auto-generated)
‚îú‚îÄ‚îÄ evidence/                      # Evidence JSON files
‚îú‚îÄ‚îÄ themes/                        # Theme JSON files
‚îú‚îÄ‚îÄ full_insights/                 # Complete destination insights
‚îî‚îÄ‚îÄ ...
```

### **Cache Maintenance**

```bash
# Check cache status
python -c "
import os
cache_files = len([f for f in os.listdir('cache') if f.endswith('.json')])
cache_size = sum(os.path.getsize(os.path.join('cache', f)) for f in os.listdir('cache'))
print(f'Cache files: {cache_files}, Size: {cache_size/(1024*1024):.2f} MB')
"

# Clear cache (if needed)
rm -rf cache/*  # Clear file cache
rm -rf chroma_db/*  # Clear vector cache (caution: rebuilds embeddings)

# Verify cache performance
python tests/performance/test_cache_performance.py --comprehensive
```

## üöÄ **Future Enhancements**

### **üß† Semantic Extraction Improvements**
- **Multi-Modal Analysis**: Process images and videos for additional priority data
- **Real-Time Updates**: Live monitoring of source changes and automatic re-extraction
- **Custom Domain Training**: Fine-tune models for specific destination types
- **Uncertainty Quantification**: Better confidence intervals and uncertainty estimates
- **Cross-Language Support**: Extract priority data from non-English sources
- **Advanced Context Understanding**: Better handling of complex pricing structures and conditions

### **Core Intelligence**
- **Advanced Local Authority Integration**: Real-time validation with local experts
- **Enhanced Seasonal Intelligence**: Weather API integration for live updates
- **Multi-language Content Analysis**: Support for analyzing content in multiple languages
- **Interactive Insight Exploration**: Web-based dashboard for exploring insights
- **Cross-destination Insight Transfer**: Learning patterns across similar destination types

### **üöÄ Caching Enhancements**
- **Cache Compression**: Reduce storage requirements by 40-60%
- **Intelligent Prefetching**: Predictive cache warming based on usage patterns
- **Distributed Caching**: Multi-node cache sharing for scalability
- **Analytics Dashboard**: Real-time cache performance monitoring

### **üîß Developer Experience**
- **API Endpoints**: RESTful API for programmatic access
- **CLI Tools**: Command-line utilities for batch processing
- **Configuration UI**: Web-based configuration management
- **Plugin System**: Extensible architecture for custom extractors

## üìä **Project Status**

### **‚úÖ Production Ready**
- **163 Tests Passing** (100% success rate)
- **Semantic extraction** fully implemented and tested
- **Multiple LLM providers** supported with auto-detection
- **Comprehensive error handling** and fallback modes
- **Performance optimized** with 4-layer caching
- **Database schema** enhanced for semantic data
- **Documentation** complete and current

### **üîß Recently Completed**
- **Semantic Priority Data Extraction**: Complete LLM-powered replacement of regex system
- **Test Suite Updates**: All 163 tests updated and passing
- **Fallback Mode Implementation**: Graceful degradation when LLM unavailable
- **LLM Provider Flexibility**: Support for both Gemini and OpenAI
- **Integration Testing**: End-to-end validation of semantic features

### **üìà Performance Metrics**
- **Test Success Rate**: 100% (163/163 tests passing)
- **Cache Performance**: 5,575x API improvement, 70x content processing
- **Semantic Accuracy**: Context-aware extraction with confidence scoring
- **System Reliability**: Robust fallback and error handling

## ü§ù **Contributing**

### **Development Setup**
```bash
# Clone and setup
git clone <repository-url>
cd DestinationIntelligence
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Setup configuration
cp .env.example .env
cp config.yaml.example config.yaml
# Add your API keys to .env

# Run tests to verify setup
python tests/run_all_tests.py
```

### **Testing Guidelines**
- **Always run full test suite** before submitting PRs
- **Add tests for new features**, especially semantic extraction enhancements
- **Maintain 100% test success rate**
- **Test both semantic and fallback modes** for new priority data features

### **Code Quality**
- **Follow existing patterns** for LLM integration and error handling
- **Add comprehensive logging** for debugging
- **Include fallback modes** for external dependencies
- **Document configuration options** and their effects

## üìú **License**

This project is licensed under the MIT License - see the LICENSE file for details.

---

## üéâ **Quick Start Summary**

1. **Clone repository** and install dependencies
2. **Add API keys** (GEMINI_API_KEY and BRAVE_SEARCH_API_KEY required)
3. **Run application**: `python run_enhanced_agent_app.py`
4. **Verify tests**: `python tests/run_all_tests.py` (163 tests should pass)
5. **Explore results** in `outputs/completed_processing/` and `destination_insights/`

**Ready to discover intelligent destination insights with semantic understanding!** üöÄ‚ú® 